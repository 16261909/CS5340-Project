{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:14.353429Z",
     "start_time": "2024-04-15T10:31:14.338572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ],
   "id": "eac6ac36111d2c2a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.815910Z",
     "start_time": "2024-04-15T10:31:14.354728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from config import *\n",
    "from utilities import *\n",
    "from resnet import MyResNet"
   ],
   "id": "ab758440cd6fae0a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.820918Z",
     "start_time": "2024-04-15T10:31:15.816715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_imageset_path = '../trainval/DAVIS/ImageSets/2017/train.txt'\n",
    "val_imageset_path = '../trainval/DAVIS/ImageSets/2017/val.txt'\n",
    "testd_imageset_path = '../testd/DAVIS/ImageSets/2017/test-dev.txt'\n",
    "\n",
    "train_flow_root = '../flow/trainval/'\n",
    "testd_flow_root = '../flow/test/'\n",
    "result_root = '../result/mrf/'\n",
    "trainval_image_root = '../trainval/DAVIS/JPEGImages/480p/'\n",
    "trainval_mask_root = '../trainval/DAVIS/Annotations/480p/'\n",
    "testd_image_root = '../testd/DAVIS/JPEGImages/480p/'\n",
    "testd_mask_root = '../testd/DAVIS/Annotations/480p/'\n",
    "rough_annotation_root = '../rough_annotation/osvos/'\n",
    "models_root = '../models/'\n",
    "gif_root = '../gif/'\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "testd_list = []\n",
    "\n",
    "with open(train_imageset_path, 'r') as f:\n",
    "    for line in f:\n",
    "        train_list.append(line.strip())\n",
    "with open(val_imageset_path, 'r') as f:\n",
    "    for line in f:\n",
    "        val_list.append(line.strip())\n",
    "with open(testd_imageset_path, 'r') as f:\n",
    "    for line in f:\n",
    "        testd_list.append(line.strip())\n",
    "\n",
    "print(val_list)\n",
    "\n",
    "precomputed_positions = None\n",
    "mask = None\n",
    "osvos_mask = None\n",
    "flo = None\n",
    "imgs = None\n",
    "gray_imgs = None\n",
    "cnn_mask = None\n",
    "model = None\n",
    "color_to_gray_map = {}\n",
    "gray_to_color_map = {}\n",
    "\n",
    "# soapbox 29\n",
    "# dogs-jump 10\n",
    "# gold-fish 14\n",
    "# pigs 26"
   ],
   "id": "654d27d4ee0d523a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bike-packing', 'blackswan', 'bmx-trees', 'breakdance', 'camel', 'car-roundabout', 'car-shadow', 'cows', 'dance-twirl', 'dog', 'dogs-jump', 'drift-chicane', 'drift-straight', 'goat', 'gold-fish', 'horsejump-high', 'india', 'judo', 'kite-surf', 'lab-coat', 'libby', 'loading', 'mbike-trick', 'motocross-jump', 'paragliding-launch', 'parkour', 'pigs', 'scooter-black', 'shooting', 'soapbox']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.846466Z",
     "start_time": "2024-04-15T10:31:15.821854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_positions( pos, t):\n",
    "    \n",
    "    global precomputed_positions\n",
    "    \n",
    "    if (precomputed_positions[t, pos[0], pos[1]] != not_calculated_err).all():\n",
    "        return precomputed_positions[t, pos[0], pos[1], 0], precomputed_positions[t, pos[0], pos[1], 1]\n",
    "\n",
    "    # [-flow_range, -flow_range + 1, ..., -1, 1, ..., flow_range - 1, flow_range]\n",
    "    precomputed_positions[t, pos[0], pos[1], 0] = np.full((flow_range, 2), out_of_range_err)\n",
    "    precomputed_positions[t, pos[0], pos[1], 1] = np.full((flow_range, 2), out_of_range_err)\n",
    "    cur_pos = list(pos)\n",
    "    # Loop from 0 to flow_range\n",
    "    for offset in range(min(flow_range, precomputed_positions.shape[0] - t - 1)):\n",
    "        flow = flo[t + offset]\n",
    "        dx, dy = flow[cur_pos[0], cur_pos[1]]\n",
    "        cur_pos = [round(cur_pos[0] + dx), round(cur_pos[1] + dy)]\n",
    "        if cur_pos[0] < 0 or cur_pos[0] >= flo.shape[1] or cur_pos[1] < 0 or cur_pos[1] >= flo.shape[2]:\n",
    "            break\n",
    "        precomputed_positions[t, pos[0], pos[1], 1, offset] = [cur_pos[0], cur_pos[1]]\n",
    "        precomputed_positions[t + offset + 1, cur_pos[0], cur_pos[1], 0, offset] = [pos[0], pos[1]]\n",
    "\n",
    "    cur_pos = list(pos)\n",
    "    # Loop from 0 to -flow_range\n",
    "    for offset in range(min(flow_range, t - 1)):\n",
    "        flow = flo[t - offset]\n",
    "        dx, dy = flow[cur_pos[0], cur_pos[1]]\n",
    "        cur_pos = [round(cur_pos[0] - dx), round(cur_pos[1] - dy)]\n",
    "        if cur_pos[0] < 0 or cur_pos[0] >= flo.shape[1] or cur_pos[1] < 0 or cur_pos[1] >= flo.shape[2]:\n",
    "            break\n",
    "        precomputed_positions[t, pos[0], pos[1], 0, offset] = [cur_pos[0], cur_pos[1]]\n",
    "        precomputed_positions[t - offset - 1, cur_pos[0], cur_pos[1], 1, offset] = [pos[0], pos[1]]\n",
    "\n",
    "    return precomputed_positions[t, pos[0], pos[1], 0], precomputed_positions[t, pos[0], pos[1], 1]"
   ],
   "id": "5b122f66751d4131",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.862093Z",
     "start_time": "2024-04-15T10:31:15.847481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def energy(args):\n",
    "    t, x, y, value = args\n",
    "\n",
    "    global mask, osvos_mask, precomputed_positions, cnn_mask\n",
    "\n",
    "    if precomputed_positions is None:\n",
    "        raise ValueError(\"precomputed_positions must be initialized before calling this function.\")\n",
    "\n",
    "    idx = (t, x, y)\n",
    "    e_u, e_t, e_s = 0, 0, 0\n",
    "\n",
    "    e_u += -log_e_u_false_possibility if value != osvos_mask[idx] else -log_e_u_true_possibility\n",
    "\n",
    "    # -1 -> -flow_range\n",
    "    for dt in range(min(flow_range, t - 1)):\n",
    "        if precomputed_positions[t, x, y, 0, dt, 0] == out_of_range_err:\n",
    "            break\n",
    "        # print(f'{t}, {dt}, {x}, {y}, {precomputed_positions[t, x, y, 0, dt, 0]}, {precomputed_positions[t, x, y, 0, dt, 1]}')\n",
    "        e_t += time_parameter(t - dt - 1) * time_parameter(t) * (1 if value != mask[t - dt - 1, precomputed_positions[t, x, y, 0, dt, 0], precomputed_positions[t, x, y, 0, dt, 1]] else 0) ** 2\n",
    "\n",
    "    # 1 -> flow_range\n",
    "    for dt in range(min(flow_range, mask.shape[0] - t - 1)):\n",
    "        if precomputed_positions[t, x, y, 1, dt, 0] == out_of_range_err:\n",
    "            break\n",
    "        e_t += time_parameter(t + dt + 1) * time_parameter(t) * (1 if value != mask[t + dt + 1, precomputed_positions[t, x, y, 1, dt, 0], precomputed_positions[t, x, y, 1, dt, 1]] else 0) ** 2\n",
    "        \n",
    "    e_s = (value != cnn_mask[idx]) * 1\n",
    "    \n",
    "    return theta_u * e_u + theta_t * e_t + theta_s * s_parameter(t) * e_s"
   ],
   "id": "450029434a5f3261",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.877416Z",
     "start_time": "2024-04-15T10:31:15.862777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init():\n",
    "\n",
    "    global precomputed_positions\n",
    "\n",
    "    shape = mask.shape\n",
    "    precomputed_positions = np.empty((shape[0], shape[1], shape[2], 2, flow_range, 2), dtype=tuple)\n",
    "    precomputed_positions.fill(not_calculated_err)\n",
    "\n",
    "    for t in range(shape[0]):\n",
    "        for x in range(shape[1]):\n",
    "            for y in range(shape[2]):\n",
    "                neg_ret, pos_ret = get_positions((x, y), t)\n",
    "                precomputed_positions[t, x, y, 0] = neg_ret\n",
    "                precomputed_positions[t, x, y, 1] = pos_ret\n"
   ],
   "id": "b9c2c3116a25a853",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.888148Z",
     "start_time": "2024-04-15T10:31:15.878430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cnn_eval():\n",
    "    global mask, cnn_mask, imgs, model\n",
    "    x = torch.tensor(np.concatenate((imgs.reshape(-1, 3, imgs.shape[1], imgs.shape[2]) / 255, np.expand_dims(mask, axis=1)), axis=1)).float().to(device)\n",
    "    \n",
    "    num_samples = len(x)\n",
    "    all_outputs = []\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_x = x[i:min(i+batch_size, num_samples)].to(device)\n",
    "        batch_output = model(batch_x)\n",
    "        all_outputs.append(batch_output)\n",
    "    y = torch.cat(all_outputs, dim=0)\n",
    "    cnn_mask = np.argmax(y.cpu().detach().numpy(), axis=1).reshape(mask.shape)   "
   ],
   "id": "df969a4b260b913f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.905532Z",
     "start_time": "2024-04-15T10:31:15.888884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# image_root = train_image_root\n",
    "# mask_root = train_mask_root\n",
    "# target_list = val_list\n",
    "def eval(image_root, mask_root, flow_root, target_list, result_root='../result/mrf/', data = None):\n",
    "    global mask, osvos_mask, flo, imgs, gray_imgs, cnn_mask, gray_to_color_map, color_to_gray_map, model\n",
    "    for p in range(len(target_list)):\n",
    "        if data is not None and p != data:\n",
    "            continue\n",
    "        image_path = os.path.join(image_root, target_list[p])\n",
    "        mask_path = os.path.join(mask_root, target_list[p] + '/00000.png')\n",
    "        osvos_path = os.path.join(rough_annotation_root, target_list[p])\n",
    "        result_path = os.path.join(result_root, target_list[p])\n",
    "        flow_path = os.path.join(flow_root, target_list[p])\n",
    "        model_save_path = os.path.join(models_root, target_list[p] + '.pt')\n",
    "    \n",
    "        image_list = sorted(os.listdir(image_path))\n",
    "        image_list = image_list[:]\n",
    "        mask = cv2.imread(mask_path)\n",
    "        PIL_mask = Image.open(mask_path)\n",
    "        color_to_gray_map, gray_to_color_map = get_map(mask, PIL_mask)\n",
    "        del PIL_mask\n",
    "        \n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        mask = np.tile(mask, (len(image_list), 1, 1, 1))\n",
    "        imgs = np.zeros_like(mask)\n",
    "        osvos_mask = np.zeros_like(mask)\n",
    "        mask = convert_to_gray_mask(mask, color_to_gray_map)\n",
    "        gray_imgs = np.zeros_like(mask)\n",
    "    \n",
    "        type_cnt = len(color_to_gray_map)\n",
    "        print('type_cnt:', type_cnt)\n",
    "    \n",
    "        for i in range(len(image_list)):\n",
    "            osvos_mask[i] = cv2.imread(os.path.join(osvos_path, f\"{i:05d}.png\"))\n",
    "    \n",
    "        osvos_mask = convert_to_gray_mask(osvos_mask, color_to_gray_map)\n",
    "        osvos_mask[0] = mask[0] \n",
    "    \n",
    "        resized_osvos_mask = np.zeros((mask.shape[0], Resize[1], Resize[0]))\n",
    "    \n",
    "        for i in range(mask.shape[0]):\n",
    "            resized_osvos_mask[i] = cv2.resize(osvos_mask[i], Resize, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "        mask = resized_osvos_mask\n",
    "        osvos_mask = resized_osvos_mask\n",
    "        flo = np.zeros_like(mask)\n",
    "        flo = np.tile(np.expand_dims(flo, axis=-1), (1, 1, 1, 2))\n",
    "        del resized_osvos_mask\n",
    "    \n",
    "        resized_imgs = np.zeros((mask.shape[0], Resize[1], Resize[0], 3), dtype=np.uint8)\n",
    "        for i in range(len(image_list)):\n",
    "            cv2.imread(os.path.join(image_path, f\"{i:05d}.jpg\"))\n",
    "            imgs[i] = cv2.imread(os.path.join(image_path, f\"{i:05d}.jpg\"))\n",
    "            imgs[i] = cv2.cvtColor(imgs[i], cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        for i in range(len(image_list)):\n",
    "            resized_imgs[i] = cv2.resize(imgs[i], Resize, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "        imgs = resized_imgs\n",
    "        del resized_imgs\n",
    "        # gray_imgs = np.zeros((mask.shape[0], Resize[1], Resize[0]), dtype=np.uint8)\n",
    "    \n",
    "        # for i in range(len(image_list)):\n",
    "        #     gray_imgs[i] = cv2.cvtColor(imgs[i], cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "        for i in range(len(image_list) - 1):\n",
    "            # flo[i] = cv2.calcOpticalFlowFarneback(gray_imgs[i], gray_imgs[i + 1], None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            flo[i] = resize_flo(read_flo_file(os.path.join(flow_path, f\"{i:06d}.flo\"))) \n",
    "            \n",
    "        flo = filter_unreliable_flow(flo)\n",
    "        print('Precomputing positions from optical flow...')\n",
    "        init()\n",
    "        \n",
    "        \n",
    "        model = MyResNet(len(color_to_gray_map)).to(device)\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        model.eval()\n",
    "        \n",
    "        cnn_eval()\n",
    "        mask = cnn_mask\n",
    "        for _ in range(total_iter):\n",
    "            with Pool() as pool:\n",
    "                for _ in tqdm(range(ICM_iter)):\n",
    "                    tasks = [(t, x, y, k) for t in range(len(image_list)) for x in range(mask.shape[1]) for y in\n",
    "                             range(mask.shape[2]) for k in range(type_cnt)]\n",
    "                    e_results = np.array(list(pool.map(energy, tasks)))\n",
    "                    e_results = np.array(e_results).reshape((len(image_list), mask.shape[1], mask.shape[2], type_cnt))\n",
    "                    mask = np.argmin(e_results, axis=-1)\n",
    "                    \n",
    "            cnn_eval()\n",
    "        # for o in range(mask.shape[0]):\n",
    "        #     print_images([imgs[o], mask[o], cnn_mask[o], osvos_mask[o]])\n",
    "                \n",
    "        print('ICM done')\n",
    "        \n",
    "        # write\n",
    "        if os.path.exists(result_path):\n",
    "            shutil.rmtree(result_path)\n",
    "        os.makedirs(result_path)\n",
    "        \n",
    "        resized_mask = np.zeros((mask.shape[0], OriginalSize[1], OriginalSize[0]))\n",
    "        for i in range(len(image_list)):\n",
    "            resized_mask[i] = cv2.resize(mask[i], OriginalSize, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        for i in range(len(image_list)):\n",
    "            result_i_path = result_path + f\"/{i:05d}.png\"\n",
    "            cv2.imwrite(result_i_path, restore_color_mask(resized_mask[i], gray_to_color_map))\n",
    "        \n",
    "        del resized_mask\n"
   ],
   "id": "b3b7c2acad819274",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:31:15.920620Z",
     "start_time": "2024-04-15T10:31:15.906497Z"
    }
   },
   "cell_type": "code",
   "source": "data = 29",
   "id": "2e1f6ddec2379958",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:33:26.034312Z",
     "start_time": "2024-04-15T10:31:15.921985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_iter = 1 # 3\n",
    "theta_u = 0 # 1\n",
    "theta_t = 1 # 3\n",
    "theta_s = 0 # 1.5\n",
    "eval(trainval_image_root, trainval_mask_root, train_flow_root, val_list, '../result/mrf_t/', data)"
   ],
   "id": "301e95f59fc16bc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_cnt: 4\n",
      "Precomputing positions from optical flow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevenzhang/miniconda3/envs/vnn/lib/python3.10/site-packages/segmentation_models_pytorch/base/modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.77 GiB total capacity; 4.52 GiB already allocated; 31.00 MiB free; 4.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m theta_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# 3\u001B[39;00m\n\u001B[1;32m      4\u001B[0m theta_s \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;66;03m# 1.5\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;43meval\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrainval_image_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainval_mask_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_flow_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../result/mrf_t/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 79\u001B[0m, in \u001B[0;36meval\u001B[0;34m(image_root, mask_root, flow_root, target_list, result_root, data)\u001B[0m\n\u001B[1;32m     76\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(model_save_path))\n\u001B[1;32m     77\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m---> 79\u001B[0m \u001B[43mcnn_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m mask \u001B[38;5;241m=\u001B[39m cnn_mask\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(total_iter):\n",
      "Cell \u001B[0;32mIn[7], line 9\u001B[0m, in \u001B[0;36mcnn_eval\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, num_samples, batch_size):\n\u001B[1;32m      8\u001B[0m     batch_x \u001B[38;5;241m=\u001B[39m x[i:\u001B[38;5;28mmin\u001B[39m(i\u001B[38;5;241m+\u001B[39mbatch_size, num_samples)]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 9\u001B[0m     batch_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     all_outputs\u001B[38;5;241m.\u001B[39mappend(batch_output)\n\u001B[1;32m     11\u001B[0m y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(all_outputs, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/codes/cs5340project/code/resnet.py:14\u001B[0m, in \u001B[0;36mMyResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:29\u001B[0m, in \u001B[0;36mSegmentationModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_input_shape(x)\n\u001B[0;32m---> 29\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m decoder_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(\u001B[38;5;241m*\u001B[39mfeatures)\n\u001B[1;32m     32\u001B[0m masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msegmentation_head(decoder_output)\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/resnet.py:62\u001B[0m, in \u001B[0;36mResNetEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     60\u001B[0m features \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 62\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mstages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m     features\u001B[38;5;241m.\u001B[39mappend(x)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m features\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torchvision/models/resnet.py:96\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     93\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(out)\n\u001B[1;32m     94\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m---> 96\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(out)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/vnn/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    450\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    451\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    452\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.77 GiB total capacity; 4.52 GiB already allocated; 31.00 MiB free; 4.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_iter = 3 # 3\n",
    "theta_u = 1 # 1\n",
    "theta_t = 3 # 3\n",
    "theta_s = 1.5 # 1.5\n",
    "eval(trainval_image_root, trainval_mask_root, train_flow_root, val_list, '../result/mrf_e_t_s/', data)"
   ],
   "id": "7cd1843cd67705b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_iter = 1 # 3\n",
    "theta_u = 1 # 1\n",
    "theta_t = 3 # 3\n",
    "theta_s = 0 # 1.5\n",
    "eval(trainval_image_root, trainval_mask_root, train_flow_root, val_list, '../result/mrf_e_t/', data)"
   ],
   "id": "316e3c8af57f0702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_iter = 1 # 3\n",
    "theta_u = 1 # 1\n",
    "theta_t = 0 # 3\n",
    "theta_s = 0 # 1.5\n",
    "eval(trainval_image_root, trainval_mask_root, train_flow_root, val_list, '../result/mrf_e/', data)"
   ],
   "id": "2169b57c636ba3e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_iter = 0 # 3\n",
    "eval(trainval_image_root, trainval_mask_root, train_flow_root, val_list, '../result/mrf_s/', data)"
   ],
   "id": "1b0d608ba398a08b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for p in range(30):\n",
    "    if p != data:\n",
    "        continue\n",
    "    if (os.path.exists(gif_root + val_list[p] + '/')):\n",
    "        shutil.rmtree(gif_root + val_list[p] + '/')\n",
    "        \n",
    "    os.makedirs(gif_root + val_list[p] + '/')\n",
    "    \n",
    "    # generate_gif(os.path.join(trainval_image_root, val_list[p] + '/'), os.path.join(trainval_mask_root, val_list[p] + '/'), '../result/mrf_e_t_s/' + val_list[p] + '/', gif_root + val_list[p] + '/' + 'mrf_e_t_s'+ '.gif') \n",
    "    # \n",
    "    # generate_gif(os.path.join(trainval_image_root, val_list[p] + '/'), os.path.join(trainval_mask_root, val_list[p] + '/'), '../result/mrf_e_t/' + val_list[p] + '/', gif_root + val_list[p] + '/' + 'mrf_e_t'+ '.gif') \n",
    "    # \n",
    "    # generate_gif(os.path.join(trainval_image_root, val_list[p] + '/'), os.path.join(trainval_mask_root, val_list[p] + '/'), '../result/mrf_t/' + val_list[p] + '/', gif_root + val_list[p] + '/' + 'mrf_t'+ '.gif') \n",
    "    # \n",
    "    # generate_gif(os.path.join(trainval_image_root, val_list[p] + '/'), os.path.join(trainval_mask_root, val_list[p] + '/'), '../result/mrf_e/' + val_list[p] + '/', gif_root + val_list[p] + '/' + 'mrf_e'+ '.gif') \n",
    "    # \n",
    "    # generate_gif(os.path.join(trainval_image_root, val_list[p] + '/'), os.path.join(trainval_mask_root, val_list[p] + '/'), '../result/mrf_s/' + val_list[p] + '/', gif_root + val_list[p] + '/' + 'mrf_s'+ '.gif') \n",
    "    \n",
    "    generate_result(os.path.join(trainval_image_root, val_list[p] + '/'), os.path.join(trainval_mask_root, val_list[p] + '/'),  '../result/mrf_e/' + val_list[p] + '/', '../result/mrf_t/' + val_list[p] + '/', '../result/mrf_e_t/' + val_list[p] + '/', '../result/mrf_e_t_s/' + val_list[p] + '/', gif_root + val_list[p] + '/' + 'result'+ '.gif')"
   ],
   "id": "adceec08f18170e5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs5340)",
   "language": "python",
   "name": "cs5340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
